{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"ParShift","text":"<p>ParShift is a python package based on Gibson's framework for the analysis of conversational sequences.</p> <p>The framework is established on the concept of participation shift, which refers to the shifting of individuals between the positions of speaker, target (addressee), and non-addressee (everyone else), in a group conversation.</p>"},{"location":"#installation","title":"Installation","text":""},{"location":"#from-pypi","title":"From PyPI","text":"<pre><code>pip install parshift\n</code></pre>"},{"location":"#from-source","title":"From source","text":"<p>Directly using <code>pip</code>:</p> <pre><code>pip install git+https://github.com/bdfsaraiva/parshift.git#egg=parshift\n</code></pre> <p>Or each step at a time:</p> <pre><code>git clone https://github.com/bdfsaraiva/parshift\ncd parshift\npip install .\n</code></pre>"},{"location":"#getting-started","title":"Getting Started","text":"<p>For an in-depth overview of the features of ParShift can follow along with one of the examples below:</p> Name Link Participation Shifts with ParShift"},{"location":"#further-reading","title":"Further reading","text":"<ul> <li>Function reference</li> <li>Development reference</li> </ul>"},{"location":"#license","title":"License","text":"<p>MIT License</p>"},{"location":"dev/","title":"Development","text":""},{"location":"dev/#installing-for-development-andor-improving-the-package","title":"Installing for development and/or improving the package","text":"<pre><code>$ git clone https://github.com/bdfsaraiva/parshift\n$ cd parshift\n$ python -m venv env\n$ source env/bin/activate\n$ pip install -e .[dev]\n</code></pre> <p>On Windows replace <code>source env/bin/activate</code> with <code>. env\\Scripts\\activate</code>.</p>"},{"location":"dev/#run-tests","title":"Run tests","text":"<p>Test can be run with the following command:</p> <pre><code>$ pytest\n</code></pre> <p>To generate an HTML page with coverage data, do the following:</p> <pre><code>$ pytest --cov=parshift --cov-report=html\n</code></pre> <p>Then open the generated <code>htmlcov/index.html</code> file in your browser to see the coverage HTML site.</p>"},{"location":"dev/#build-docs","title":"Build docs","text":"<p>Considering we're in the <code>parshift</code> project folder, run the following commands:</p> <pre><code>$ cd docs\n$ mkdocs build\n</code></pre> <p>The generated documentation will be placed in <code>docs/site</code>. Alternatively, the documentation can be generated and served locally with:</p> <pre><code>$ mkdocs serve\n</code></pre>"},{"location":"dev/#code-style","title":"Code style","text":"<p>ParShift's source code follows the black style.</p>"},{"location":"reference/","title":"Reference","text":"<p>API reference for the functions exported by ParShift.</p>"},{"location":"reference/#parshift.Parshift","title":"Parshift","text":"Source code in <code>/home/runner/work/parshift/parshift/parshift/oo_parshift.py</code> <pre><code>class Parshift:\n    def __init__(\n        self,\n        annotation: pd.DataFrame | None = None,\n        stats: pd.DataFrame | List[pd.DataFrame] | None = None,\n    ):\n\"\"\"Parshift initialization\"\"\"\n\n        self.annotation = annotation\n        self.stats = stats\n\n    def process(\n        self,\n        filepath_or_buffer: FilePath | ReadCsvBuffer[bytes] | ReadCsvBuffer[str],\n        N: int = 1,\n        **kwargs: Any,\n    ):\n\"\"\"Read a conversation file in CSV format, validate it,\n        get Gibson's participation shift codes from turns in a conversation,\n        determine the conditional probabilities for a sequence of participation shift codes\n        and return a dict with parshift annotations and conditional probabilities.\n\n        The conversation file should have the following columns:\n\n        - `utterance_id`: ID of the message (int)\n        - `speaker_id`: ID of the user sending the message (str)\n        - `utterance`: The message itself (string)\n        - `reply_to_id` or `target_id`: The reply ID or the target ID (int)\n\n        Arguments:\n            filepath_or_buffer: Any valid string path to CSV file, as accepted by\n                Pandas [`read_csv()`][pandas.read_csv] function.\n            N: Number of parts to split the conversation into. Default is 1 (all conversation).\n                `N` should be between 1 and 4.\n            **kwargs: Keyword parameters passed to Pandas\n                [`read_csv()`][pandas.read_csv] function.\n\n        - Parshift.annotation will be data frame equal as returned by [`annotate()`][parshift.annotation.annotate].\n        - Parshift.stats will be data frame equal as returned by [`cond_probs()`][parshift.statistics.cond_probs].\n        \"\"\"\n\n        df_annotate = annotate(read_ccsv(filepath_or_buffer, **kwargs))\n        self.annotation = df_annotate\n\n        if N == 1:\n            self.stats = cond_probs(df_annotate)\n        elif N in [2, 3, 4]:\n            list_stats = []\n            size = len(df_annotate)\n            parts = size / N\n            for i in range(N):\n                # Get all the rows from parts*i to size*(i+1) with all columns\n                start = int(parts * i)\n                end = int(parts * (i + 1))\n                list_stats.append(cond_probs(df_annotate.iloc[start:end, :]))\n            self.stats = list_stats\n        else:\n            raise ValueError(\"N should be between 1 and 4.\")\n\n    def show_plot(self, type: str = \"Pshift\", filename: str | None = None):\n\"\"\"Shows the frequency treemap plot returned by [`frequency_treemap()`][parshift.plotting.frequency_treemap]\n\n        Arguments:\n            type: Column name to be used to plot the treemap, either `\"Pshift\"`\n                (default) or `\"Pshift_class\"`.\n            filename: Name of the file to save the plot. Default to `None` .\n\n        \"\"\"\n\n        if self.stats is None:\n            raise ValueError(\n                \"Parshift.stats is None. Please run Parshift.process() first.\"\n            )\n\n        if not isinstance(type, str):\n            raise TypeError(\"Parameter type must be a String\")\n        if type not in [\"Pshift_class\", \"Pshift\"]:\n            raise ValueError(\n                \"Parameter type must be one of the following: `Pshift`, `Pshift_class`\"\n            )\n\n        if filename != None and not isinstance(filename, str):\n            raise TypeError(\"Parameter filename must be a String\")\n\n        if type == \"Pshift\":\n            if isinstance(self.stats, list):\n                _, ax = plt.subplots(\n                    1, len(self.stats), figsize=(5 * len(self.stats), 5)\n                )\n\n                for i in range(len(self.stats)):\n                    frequency_treemap(self.stats[i], type=type, ax=ax[i])\n                    ax[i].axis(\"off\")\n                    ax[i].set_title(f\"n {i+1}\")\n            else:\n                ax = frequency_treemap(self.stats, type=type)\n\n            plt.suptitle(\"Participation-Shift Frequencies\")\n\n        elif type == \"Pshift_class\":\n            if isinstance(self.stats, list):\n                _, ax = plt.subplots(\n                    1, len(self.stats), figsize=(5 * len(self.stats), 5)\n                )\n\n                for i in range(len(self.stats)):\n                    frequency_treemap(self.stats[i], type=type, ax=ax[i])\n                    ax[i].axis(\"off\")\n                    ax[i].set_title(f\"n {i+1}\")\n            else:\n                ax = frequency_treemap(self.stats, type=type)\n\n            plt.suptitle(\"Participation Shifts: Class Proportions\")\n\n        if filename:\n            if \".png\" not in filename:\n                filename += \".png\"\n            plt.savefig(filename, dpi=300)\n\n        plt.show()\n\n    def show_stats(self, filename: str | None = None):\n\"\"\"Prints the stats returned by [`cond_probs()`][parshift.statistics.cond_probs]\n        Dataframe. If kwarg N (see [`process`][parshift.Parshift.process]) &gt; 1, prints N data frames.\n\n        Arguments:\n            filename: Name of the file (csv) to save the stats data frame. Default to `None`.\n        \"\"\"\n\n        if self.stats is None:\n            raise ValueError(\n                \"Parshift.stats is None. Please run Parshift.process() first.\"\n            )\n\n        if isinstance(self.stats, list):\n            for i in range(len(self.stats)):\n                print(f\"n{i+1}:\")\n                print(self.stats[i])\n                print(\"-\" * 80)\n\n                if filename:\n                    if \".csv\" not in filename:\n                        filename_changed = f\"{filename}_n{i+1}.csv\"\n                    else:\n                        filename_changed = filename.replace(\".csv\", f\"_n{i+1}.csv\")\n                    self.stats[i].to_csv(filename_changed, index=False)\n\n        else:\n            print(self.stats)\n            if filename:\n                if \".csv\" not in filename:\n                    filename += \".csv\"\n                self.stats.to_csv(filename, index=False)\n\n    def get_propensities(self, filename: str | None = None) -&gt; pd.DataFrame:\n\"\"\"Returns a data frame with the Participation Shift propensities.\n\n        Arguments:\n            filename: Name of the file (csv) to save the propensities data frame. Default to `None`.\n\n        Returns:\n            A Pandas [`DataFrame`][pandas.DataFrame] containing the propensities.\n        \"\"\"\n\n        if self.stats is None:\n            raise ValueError(\n                \"Parshift.stats is None. Please run Parshift.process() first.\"\n            )\n\n        if isinstance(self.stats, list):\n            df = propensities(self.stats[0])\n            df.index = [\"n1\"]  # type: ignore\n            for i in range(1, len(self.stats)):\n                dfx = propensities(self.stats[i])\n                dfx.index = [f\"n{i+1}\"]  # type: ignore\n                df = pd.concat([df, dfx])\n\n            if filename:\n                if \".csv\" not in filename:\n                    filename += \".csv\"\n                df.to_csv(filename, index=False)\n            return df\n\n        else:\n            df = propensities(self.stats)\n            df.index = [\"n\"]  # type: ignore\n\n            if filename:\n                if \".csv\" not in filename:\n                    filename += \".csv\"\n                df.to_csv(filename, index=False)\n            return df\n</code></pre>"},{"location":"reference/#parshift.oo_parshift.Parshift.__init__","title":"__init__","text":"<pre><code>__init__(\n    annotation: pd.DataFrame | None = None,\n    stats: pd.DataFrame | List[pd.DataFrame] | None = None,\n)\n</code></pre> <p>Parshift initialization</p> Source code in <code>/home/runner/work/parshift/parshift/parshift/oo_parshift.py</code> <pre><code>def __init__(\n    self,\n    annotation: pd.DataFrame | None = None,\n    stats: pd.DataFrame | List[pd.DataFrame] | None = None,\n):\n\"\"\"Parshift initialization\"\"\"\n\n    self.annotation = annotation\n    self.stats = stats\n</code></pre>"},{"location":"reference/#parshift.oo_parshift.Parshift.get_propensities","title":"get_propensities","text":"<pre><code>get_propensities(filename: str | None = None) -&gt; pd.DataFrame\n</code></pre> <p>Returns a data frame with the Participation Shift propensities.</p> <p>Parameters:</p> Name Type Description Default <code>filename</code> <code>str | None</code> <p>Name of the file (csv) to save the propensities data frame. Default to <code>None</code>.</p> <code>None</code> <p>Returns:</p> Type Description <code>pd.DataFrame</code> <p>A Pandas <code>DataFrame</code> containing the propensities.</p> Source code in <code>/home/runner/work/parshift/parshift/parshift/oo_parshift.py</code> <pre><code>def get_propensities(self, filename: str | None = None) -&gt; pd.DataFrame:\n\"\"\"Returns a data frame with the Participation Shift propensities.\n\n    Arguments:\n        filename: Name of the file (csv) to save the propensities data frame. Default to `None`.\n\n    Returns:\n        A Pandas [`DataFrame`][pandas.DataFrame] containing the propensities.\n    \"\"\"\n\n    if self.stats is None:\n        raise ValueError(\n            \"Parshift.stats is None. Please run Parshift.process() first.\"\n        )\n\n    if isinstance(self.stats, list):\n        df = propensities(self.stats[0])\n        df.index = [\"n1\"]  # type: ignore\n        for i in range(1, len(self.stats)):\n            dfx = propensities(self.stats[i])\n            dfx.index = [f\"n{i+1}\"]  # type: ignore\n            df = pd.concat([df, dfx])\n\n        if filename:\n            if \".csv\" not in filename:\n                filename += \".csv\"\n            df.to_csv(filename, index=False)\n        return df\n\n    else:\n        df = propensities(self.stats)\n        df.index = [\"n\"]  # type: ignore\n\n        if filename:\n            if \".csv\" not in filename:\n                filename += \".csv\"\n            df.to_csv(filename, index=False)\n        return df\n</code></pre>"},{"location":"reference/#parshift.oo_parshift.Parshift.process","title":"process","text":"<pre><code>process(\n    filepath_or_buffer: FilePath | ReadCsvBuffer[bytes] | ReadCsvBuffer[str],\n    N: int = 1,\n    **kwargs: Any\n)\n</code></pre> <p>Read a conversation file in CSV format, validate it, get Gibson's participation shift codes from turns in a conversation, determine the conditional probabilities for a sequence of participation shift codes and return a dict with parshift annotations and conditional probabilities.</p> <p>The conversation file should have the following columns:</p> <ul> <li><code>utterance_id</code>: ID of the message (int)</li> <li><code>speaker_id</code>: ID of the user sending the message (str)</li> <li><code>utterance</code>: The message itself (string)</li> <li><code>reply_to_id</code> or <code>target_id</code>: The reply ID or the target ID (int)</li> </ul> <p>Parameters:</p> Name Type Description Default <code>filepath_or_buffer</code> <code>FilePath | ReadCsvBuffer[bytes] | ReadCsvBuffer[str]</code> <p>Any valid string path to CSV file, as accepted by Pandas <code>read_csv()</code> function.</p> required <code>N</code> <code>int</code> <p>Number of parts to split the conversation into. Default is 1 (all conversation). <code>N</code> should be between 1 and 4.</p> <code>1</code> <code>**kwargs</code> <code>Any</code> <p>Keyword parameters passed to Pandas <code>read_csv()</code> function.</p> <code>{}</code> <ul> <li>Parshift.annotation will be data frame equal as returned by <code>annotate()</code>.</li> <li>Parshift.stats will be data frame equal as returned by <code>cond_probs()</code>.</li> </ul> Source code in <code>/home/runner/work/parshift/parshift/parshift/oo_parshift.py</code> <pre><code>def process(\n    self,\n    filepath_or_buffer: FilePath | ReadCsvBuffer[bytes] | ReadCsvBuffer[str],\n    N: int = 1,\n    **kwargs: Any,\n):\n\"\"\"Read a conversation file in CSV format, validate it,\n    get Gibson's participation shift codes from turns in a conversation,\n    determine the conditional probabilities for a sequence of participation shift codes\n    and return a dict with parshift annotations and conditional probabilities.\n\n    The conversation file should have the following columns:\n\n    - `utterance_id`: ID of the message (int)\n    - `speaker_id`: ID of the user sending the message (str)\n    - `utterance`: The message itself (string)\n    - `reply_to_id` or `target_id`: The reply ID or the target ID (int)\n\n    Arguments:\n        filepath_or_buffer: Any valid string path to CSV file, as accepted by\n            Pandas [`read_csv()`][pandas.read_csv] function.\n        N: Number of parts to split the conversation into. Default is 1 (all conversation).\n            `N` should be between 1 and 4.\n        **kwargs: Keyword parameters passed to Pandas\n            [`read_csv()`][pandas.read_csv] function.\n\n    - Parshift.annotation will be data frame equal as returned by [`annotate()`][parshift.annotation.annotate].\n    - Parshift.stats will be data frame equal as returned by [`cond_probs()`][parshift.statistics.cond_probs].\n    \"\"\"\n\n    df_annotate = annotate(read_ccsv(filepath_or_buffer, **kwargs))\n    self.annotation = df_annotate\n\n    if N == 1:\n        self.stats = cond_probs(df_annotate)\n    elif N in [2, 3, 4]:\n        list_stats = []\n        size = len(df_annotate)\n        parts = size / N\n        for i in range(N):\n            # Get all the rows from parts*i to size*(i+1) with all columns\n            start = int(parts * i)\n            end = int(parts * (i + 1))\n            list_stats.append(cond_probs(df_annotate.iloc[start:end, :]))\n        self.stats = list_stats\n    else:\n        raise ValueError(\"N should be between 1 and 4.\")\n</code></pre>"},{"location":"reference/#parshift.oo_parshift.Parshift.show_plot","title":"show_plot","text":"<pre><code>show_plot(type: str = 'Pshift', filename: str | None = None)\n</code></pre> <p>Shows the frequency treemap plot returned by <code>frequency_treemap()</code></p> <p>Parameters:</p> Name Type Description Default <code>type</code> <code>str</code> <p>Column name to be used to plot the treemap, either <code>\"Pshift\"</code> (default) or <code>\"Pshift_class\"</code>.</p> <code>'Pshift'</code> <code>filename</code> <code>str | None</code> <p>Name of the file to save the plot. Default to <code>None</code> .</p> <code>None</code> Source code in <code>/home/runner/work/parshift/parshift/parshift/oo_parshift.py</code> <pre><code>def show_plot(self, type: str = \"Pshift\", filename: str | None = None):\n\"\"\"Shows the frequency treemap plot returned by [`frequency_treemap()`][parshift.plotting.frequency_treemap]\n\n    Arguments:\n        type: Column name to be used to plot the treemap, either `\"Pshift\"`\n            (default) or `\"Pshift_class\"`.\n        filename: Name of the file to save the plot. Default to `None` .\n\n    \"\"\"\n\n    if self.stats is None:\n        raise ValueError(\n            \"Parshift.stats is None. Please run Parshift.process() first.\"\n        )\n\n    if not isinstance(type, str):\n        raise TypeError(\"Parameter type must be a String\")\n    if type not in [\"Pshift_class\", \"Pshift\"]:\n        raise ValueError(\n            \"Parameter type must be one of the following: `Pshift`, `Pshift_class`\"\n        )\n\n    if filename != None and not isinstance(filename, str):\n        raise TypeError(\"Parameter filename must be a String\")\n\n    if type == \"Pshift\":\n        if isinstance(self.stats, list):\n            _, ax = plt.subplots(\n                1, len(self.stats), figsize=(5 * len(self.stats), 5)\n            )\n\n            for i in range(len(self.stats)):\n                frequency_treemap(self.stats[i], type=type, ax=ax[i])\n                ax[i].axis(\"off\")\n                ax[i].set_title(f\"n {i+1}\")\n        else:\n            ax = frequency_treemap(self.stats, type=type)\n\n        plt.suptitle(\"Participation-Shift Frequencies\")\n\n    elif type == \"Pshift_class\":\n        if isinstance(self.stats, list):\n            _, ax = plt.subplots(\n                1, len(self.stats), figsize=(5 * len(self.stats), 5)\n            )\n\n            for i in range(len(self.stats)):\n                frequency_treemap(self.stats[i], type=type, ax=ax[i])\n                ax[i].axis(\"off\")\n                ax[i].set_title(f\"n {i+1}\")\n        else:\n            ax = frequency_treemap(self.stats, type=type)\n\n        plt.suptitle(\"Participation Shifts: Class Proportions\")\n\n    if filename:\n        if \".png\" not in filename:\n            filename += \".png\"\n        plt.savefig(filename, dpi=300)\n\n    plt.show()\n</code></pre>"},{"location":"reference/#parshift.oo_parshift.Parshift.show_stats","title":"show_stats","text":"<pre><code>show_stats(filename: str | None = None)\n</code></pre> <p>Prints the stats returned by <code>cond_probs()</code> Dataframe. If kwarg N (see <code>process</code>) &gt; 1, prints N data frames.</p> <p>Parameters:</p> Name Type Description Default <code>filename</code> <code>str | None</code> <p>Name of the file (csv) to save the stats data frame. Default to <code>None</code>.</p> <code>None</code> Source code in <code>/home/runner/work/parshift/parshift/parshift/oo_parshift.py</code> <pre><code>def show_stats(self, filename: str | None = None):\n\"\"\"Prints the stats returned by [`cond_probs()`][parshift.statistics.cond_probs]\n    Dataframe. If kwarg N (see [`process`][parshift.Parshift.process]) &gt; 1, prints N data frames.\n\n    Arguments:\n        filename: Name of the file (csv) to save the stats data frame. Default to `None`.\n    \"\"\"\n\n    if self.stats is None:\n        raise ValueError(\n            \"Parshift.stats is None. Please run Parshift.process() first.\"\n        )\n\n    if isinstance(self.stats, list):\n        for i in range(len(self.stats)):\n            print(f\"n{i+1}:\")\n            print(self.stats[i])\n            print(\"-\" * 80)\n\n            if filename:\n                if \".csv\" not in filename:\n                    filename_changed = f\"{filename}_n{i+1}.csv\"\n                else:\n                    filename_changed = filename.replace(\".csv\", f\"_n{i+1}.csv\")\n                self.stats[i].to_csv(filename_changed, index=False)\n\n    else:\n        print(self.stats)\n        if filename:\n            if \".csv\" not in filename:\n                filename += \".csv\"\n            self.stats.to_csv(filename, index=False)\n</code></pre>"},{"location":"reference/#parshift.annotate","title":"annotate","text":"<pre><code>annotate(conv_df: pd.DataFrame) -&gt; pd.DataFrame\n</code></pre> <p>Get Gibson's participation shift codes from turns in a conversation.</p> <p>Sequences of messages from a speaker to the same addressee are considered to be in the same turn, and therefore will be assigned a single participation shift code.</p> <p>Parameters:</p> Name Type Description Default <code>conv_df</code> <code>pd.DataFrame</code> <p>The conversation from where to obtain the participation shift codes.</p> required <p>Returns:</p> Type Description <code>pd.DataFrame</code> <p>A data frame with the participation shift codes for each turn.</p> Source code in <code>/home/runner/work/parshift/parshift/parshift/annotation.py</code> <pre><code>def annotate(conv_df: pd.DataFrame) -&gt; pd.DataFrame:\n\"\"\"Get Gibson's participation shift codes from turns in a conversation.\n\n    Sequences of messages from a speaker to the same addressee are considered to\n    be in the same turn, and therefore will be assigned a single participation\n    shift code.\n\n    Arguments:\n        conv_df: The conversation from where to obtain the participation shift codes.\n\n    Returns:\n        A data frame with the participation shift codes for each turn.\n    \"\"\"\n\n    if not isinstance(conv_df, pd.DataFrame):\n        raise TypeError(\"Parameter conv_df must be a Pandas DataFrame\")\n\n    conversation = conv2turns(conv_df)\n\n    # part1 will take the parshift label for the previous turn\n    part_1 = \"\"\n\n    # part2 will take the parshift label for the current turn\n    part_2 = \"\"\n\n    if \"reply_to_id\" in conv_df.columns:\n        annotate_df = pd.DataFrame(\n            {\n                \"utterance_ids\": [],\n                \"speaker_id\": [],\n                \"utterance\": [],\n                \"reply_to_id\": [],\n                \"label_desc\": [],\n                \"pshift\": [],\n            }\n        )\n\n        # calculate the participation shift for each turn\n        for idx, msg in enumerate(conversation):\n            if (\n                msg[\"reply_to_id\"] == None\n                or msg[\"reply_to_id\"] == \"None\"\n                or msg[\"reply_to_id\"] == \"\"\n            ):\n                part_2 = \" \" + str(msg[\"speaker_id\"]) + \" to group\"\n            else:\n                for msgPrev in conversation[: idx + 1]:\n                    if msg[\"reply_to_id\"] in msgPrev[\"utterance_ids\"]:\n                        if (\n                            msgPrev[\"reply_to_id\"] == None\n                            or msgPrev[\"reply_to_id\"] == \"None\"\n                            or msgPrev[\"reply_to_id\"] == \"\"\n                        ):\n                            part_1 = str(msgPrev[\"speaker_id\"]) + \" to group,\"\n\n                        else:  # reply - reply\n                            for msgPrev2 in conversation[:idx]:\n                                if msgPrev[\"reply_to_id\"] in msgPrev2[\"utterance_ids\"]:\n                                    part_1 = (\n                                        str(msgPrev[\"speaker_id\"])\n                                        + \" to \"\n                                        + str(msgPrev2[\"speaker_id\"])\n                                        + \",\"\n                                    )\n\n                        part_2 = (\n                            \" \"\n                            + str(msg[\"speaker_id\"])\n                            + \" to \"\n                            + str(msgPrev[\"speaker_id\"])\n                        )\n\n            # p1p2 takes the parshift label for the previous + current turn\n            p1p2 = part_1 + part_2\n\n            # part_1 takes the part_2 label for the next iteration\n            part_1 = part_2[1:] + \",\"\n\n            # set value to \"\" for first turn\n            pshift_label = \"\"\n\n            # we cannot calculate the pshift for the first turn\n            if idx != 0:\n                pshift_label = _pshift_code(p1p2)\n\n            annotate_df.loc[len(annotate_df.index)] = [  # type: ignore\n                str(msg[\"utterance_ids\"]),\n                str(msg[\"speaker_id\"]),\n                msg[\"utterance\"],\n                str(msg[\"reply_to_id\"]),\n                p1p2,\n                pshift_label,\n            ]\n\n    elif \"target_id\" in conv_df.columns:\n        annotate_df = pd.DataFrame(\n            {\n                \"utterance_ids\": [],\n                \"speaker_id\": [],\n                \"utterance\": [],\n                \"target_id\": [],\n                \"label_desc\": [],\n                \"pshift\": [],\n            }\n        )\n\n        # calculate the participation shift for each turn\n        for idx, msg in enumerate(conversation):\n            # if msg has no target, it is directed to the group\n            if (\n                msg[\"target_id\"] == None\n                or msg[\"target_id\"] == \"None\"\n                or msg[\"target_id\"] == \"\"\n            ):\n                part_2 = \" \" + str(msg[\"speaker_id\"]) + \" to group\"\n\n            # if msg has a target, we save it\n            else:\n                part_2 = \" \" + str(msg[\"speaker_id\"]) + \" to \" + str(msg[\"target_id\"])\n\n            # p1p2 takes the parshift label for the previous + current turn\n            p1p2 = part_1 + part_2\n\n            # part_1 takes the part_2 label for the next iteration\n            part_1 = part_2[1:] + \",\"\n\n            # set value to \"\" for first turn\n            pshift_label = \"\"\n\n            # we cannot calculate the pshift for the first turn\n            if idx != 0:\n                msg[\"label\"] = p1p2\n                pshift_label = _pshift_code(p1p2)\n                msg[\"pshift\"] = pshift_label\n\n            annotate_df.loc[len(annotate_df.index)] = [  # type: ignore\n                str(msg[\"utterance_ids\"]),\n                str(msg[\"speaker_id\"]),\n                msg[\"utterance\"],\n                str(msg[\"target_id\"]),\n                p1p2,\n                pshift_label,\n            ]\n\n    annotate_df.drop(columns=[\"label_desc\"], inplace=True)\n\n    return annotate_df\n</code></pre>"},{"location":"reference/#parshift.cond_probs","title":"cond_probs","text":"<pre><code>cond_probs(pshift_codes: pd.DataFrame) -&gt; pd.DataFrame\n</code></pre> <p>Determine the conditional probabilities for a sequence of participation shift codes.</p> <p>Parameters:</p> Name Type Description Default <code>pshift_codes</code> <code>pd.DataFrame</code> <p>A sequence of participation shift code obtained with <code>annotate()</code>.</p> required <p>Returns:</p> Type Description <code>pd.DataFrame</code> <p>A data frame containing the frequency, probability and conditional probabilities (two) for each parshift code. This data frame is divided into two 'subgroups': (1) those beginning with an undirected remark (A0-); and, (2) those beginning with a directed one (AB-). The <code>P(S|D)</code> (Probability of a participation shift given a Directed or Undirected remark (D)) column contains the frequency divided by total occurrences in each subgroup, while the <code>P(S|D,C)</code> (Probability of a participation shift given a Directed or Undirected remark (D) and assuming Change of Speaker (C)) column contains the frequency divided by total occurrences in each subgroup, for each participation shift where the change of speaker occurs.</p> Source code in <code>/home/runner/work/parshift/parshift/parshift/statistics.py</code> <pre><code>def cond_probs(pshift_codes: pd.DataFrame) -&gt; pd.DataFrame:\n\"\"\"Determine the conditional probabilities for a sequence of participation shift codes.\n\n    Arguments:\n        pshift_codes: A sequence of participation shift code obtained with\n            [`annotate()`][parshift.annotation.annotate].\n\n    Returns:\n        A data frame containing the frequency, probability and conditional probabilities\n            (two) for each parshift code. This data frame is divided into two 'subgroups':\n            (1) those beginning with an undirected remark (A0-); and, (2) those beginning\n            with a directed one (AB-). The `P(S|D)` (Probability of a participation shift\n            given a Directed or Undirected remark (D)) column contains the frequency divided\n            by total occurrences in each subgroup, while the `P(S|D,C)` (Probability of\n            a participation shift given a Directed or Undirected remark (D) and assuming\n            Change of Speaker (C)) column contains the frequency divided by total occurrences\n            in each subgroup, for each participation shift where the change of speaker occurs.\n    \"\"\"\n\n    if not isinstance(pshift_codes, pd.DataFrame):\n        raise TypeError(\"Parameter parshift_annotation_df must be a Dataframe\")\n\n    frequency_table_and_counts = _frequency_table(pshift_codes)\n    freq_table = frequency_table_and_counts[0]\n\n    cond_prob = {}\n    for key in freq_table:\n        if key.split(\"-\")[0] == \"A0\":\n            if key not in [\"A0-AY\", \"AB-A0\", \"AB-AY\", \"A0-A0\"]:\n                cond_prob[key] = {\n                    \"CP\": round(freq_table[key] / frequency_table_and_counts[1], 2)\n                    if frequency_table_and_counts[1] != 0\n                    else 0,\n                    \"CPeTC\": round(freq_table[key] / frequency_table_and_counts[3], 2)\n                    if frequency_table_and_counts[3] != 0\n                    else 0,\n                }\n            else:\n                cond_prob[key] = {\n                    \"CP\": round(freq_table[key] / frequency_table_and_counts[1], 2)\n                    if frequency_table_and_counts[1] != 0\n                    else 0,\n                    \"CPeTC\": \"\",\n                }\n        else:\n            if key not in [\"A0-AY\", \"AB-A0\", \"AB-AY\", \"A0-A0\"]:\n                cond_prob[key] = {\n                    \"CP\": round(freq_table[key] / frequency_table_and_counts[2], 2)\n                    if frequency_table_and_counts[2] != 0\n                    else 0,\n                    \"CPeTC\": round(freq_table[key] / frequency_table_and_counts[4], 2)\n                    if frequency_table_and_counts[4] != 0\n                    else 0,\n                }\n            else:\n                cond_prob[key] = {\n                    \"CP\": round(freq_table[key] / frequency_table_and_counts[2], 2)\n                    if frequency_table_and_counts[2] != 0\n                    else 0,\n                    \"CPeTC\": \"\",\n                }\n\n    cond_prob_df = pd.DataFrame.from_dict(cond_prob, orient=\"index\")\n    freq = pd.DataFrame.from_dict(freq_table, orient=\"index\", columns=[\"Frequency\"])\n    freq[\"Probability\"] = round(freq[\"Frequency\"] / freq[\"Frequency\"].sum(), 2)\n\n    result = (\n        pd.concat([freq, cond_prob_df], axis=1)\n        .reset_index()\n        .rename(columns={\"index\": \"pshift\"})\n    )\n\n    result = result.sort_values(\n        by=[\"pshift\"], key=lambda x: x.map(_cp_order)\n    ).reset_index(drop=True)\n\n    result = result.iloc[:, [0, 1, 2, 3, 4]]\n\n    result[\"Change of Speaker (C)\"] = result[\"pshift\"].apply(\n        lambda ps: _change_of_speaker(ps)\n    )\n\n    result[\"Directed Remark (D)\"] = result[\"pshift\"].apply(\n        lambda ps: _targeted_remark(ps)\n    )\n\n    result.rename(\n        columns={\"pshift\": \"Pshift\", \"CP\": \"P(S|D)\", \"CPeTC\": \"P(S|D,C)\"},\n        inplace=True,\n    )\n\n    return result\n</code></pre>"},{"location":"reference/#parshift.conv2turns","title":"conv2turns","text":"<pre><code>conv2turns(conv_df: pd.DataFrame) -&gt; List[Dict[str, Any]]\n</code></pre> <p>Take a conversation data frame and group it into conversation turns.</p> <p>A turn is a group of messages sent by the same user and addressed to the same target.</p> <p>Parameters:</p> Name Type Description Default <code>conv_df</code> <code>pd.DataFrame</code> <p>The conversation from where to obtain the conversation turns.</p> required <p>Returns:</p> Type Description <code>List[Dict[str, Any]]</code> <p>A list of dictionaries, each representing a conversation turn.</p> Source code in <code>/home/runner/work/parshift/parshift/parshift/annotation.py</code> <pre><code>def conv2turns(conv_df: pd.DataFrame) -&gt; List[Dict[str, Any]]:\n\"\"\"Take a conversation data frame and group it into conversation turns.\n\n    A turn is a group of messages sent by the same user and addressed to the\n    same target.\n\n    Arguments:\n        conv_df: The conversation from where to obtain the conversation turns.\n\n    Returns:\n        A list of dictionaries, each representing a conversation turn.\n    \"\"\"\n\n    conv_df = conv_df.reset_index()\n    if \"reply_to_id\" in conv_df.columns:\n        last_col = \"reply_to_id\"\n    elif \"target_id\" in conv_df.columns:\n        last_col = \"target_id\"\n\n    conversation: List[Dict[str, Any]] = []\n    turn = 0\n\n    for index, row in conv_df.iterrows():\n        # If the row being looped has the same \"speaker_id\" and the \"last_col\" value,\n        # then merge the message text and message utterance_ids into the previous turn.\n\n        if row[last_col] == \"\" or row[last_col] == \"None\":\n            row[last_col] = None\n        row[last_col] = int(float(row[last_col])) if row[last_col] != None else None\n\n        if (\n            index != 0\n            and conversation[turn - 1][\"speaker_id\"] == row[\"speaker_id\"]\n            and conversation[turn - 1][last_col] == row[last_col]\n        ):\n            msg_join = \". \".join(\n                [conversation[turn - 1][\"utterance\"], row[\"utterance\"]]\n            )\n            list_id = conversation[turn - 1][\"utterance_ids\"] + [row[\"utterance_id\"]]\n            conversation[turn - 1][\"utterance_ids\"] = list_id\n            conversation[turn - 1][\"utterance\"] = msg_join\n\n        # Otherwise, create a new dictionary representing a new turn\n        else:\n            id = row[\"utterance_id\"]\n            speaker_id = row[\"speaker_id\"]\n            utterance = row[\"utterance\"]\n            last_col_val = row[last_col]\n\n            conversation.append(\n                {\n                    \"utterance_ids\": [id],\n                    \"speaker_id\": speaker_id,\n                    \"utterance\": utterance,\n                    last_col: last_col_val\n                    if last_col_val != \"\"\n                    and last_col_val != None\n                    and last_col_val != \"None\"\n                    else None,\n                }\n            )\n\n            # Increment the turn counter\n            turn += 1\n\n    return conversation\n</code></pre>"},{"location":"reference/#parshift.frequency_treemap","title":"frequency_treemap","text":"<pre><code>frequency_treemap(\n    cond_probs_df: pd.DataFrame, ax: matplotlib.axes.Axes = None, type: str = \"Pshift\"\n) -&gt; matplotlib.axes.Axes\n</code></pre> <p>Get a matplotlib axes object displaying the conditional probabilities or frequencies.</p> <p>Parameters:</p> Name Type Description Default <code>cond_probs_df</code> <code>pd.DataFrame</code> <p>Dataframe with information about the participation shift conditional probabilities. This data frame can be obtained with <code>cond_probs()</code></p> required <code>type</code> <code>str</code> <p>Column name to be used to plot the treemap, either <code>\"Pshift\"</code> (default) or <code>\"Pshift_class\"</code>.</p> <code>'Pshift'</code> <code>ax</code> <code>matplotlib.axes.Axes</code> <p>Matplotlib axes with the treemap plot.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>ax</code> <code>matplotlib.axes.Axes</code> <p>Matplotlib axes with the participation shifts probabilities or frequency.</p> Source code in <code>/home/runner/work/parshift/parshift/parshift/plotting.py</code> <pre><code>def frequency_treemap(\n    cond_probs_df: pd.DataFrame,\n    ax: matplotlib.axes.Axes = None,\n    type: str = \"Pshift\",\n) -&gt; matplotlib.axes.Axes:\n\"\"\"Get a matplotlib axes object displaying the conditional probabilities or frequencies.\n\n    Arguments:\n        cond_probs_df: Dataframe with information about the participation shift\n            conditional probabilities. This data frame can be obtained with\n            [`cond_probs()`][parshift.statistics.cond_probs]\n        type: Column name to be used to plot the treemap, either `\"Pshift\"`\n            (default) or `\"Pshift_class\"`.\n        ax: Matplotlib axes with the treemap plot.\n\n    Returns:\n        ax: Matplotlib axes with the participation shifts probabilities or frequency.\n    \"\"\"\n\n    if not isinstance(type, str):\n        raise TypeError(\"Parameter filename must be a String\")\n    if type not in [\"Pshift_class\", \"Pshift\"]:\n        raise ValueError(\n            \"Parameter type must be one of the following: `Pshift`, `Pshift_class`\"\n        )\n\n    if type == \"Pshift_class\":\n        cond_probs_df[\"Pshift_class\"] = cond_probs_df[\"Pshift\"].apply(pshift_class)\n\n    gb_parshift = cond_probs_df.groupby([type])[\"Frequency\"].sum()\n\n    data = [\n        el\n        for el in list(zip(gb_parshift.values, gb_parshift.index.values))\n        if el[0] != 0\n    ]\n    labels = [\n        f\"{el} \\n {round( 100 * (list(zip(*data))[0][idx] / sum(list(list(zip(*data))[0]))),1)}%\"\n        for idx, el in enumerate(list(zip(*data))[1])\n    ]\n\n    color_dict = {\n        \"Turn Receiving\": \"#86d87c\",\n        \"AB-BA\": \"#86d87c\",\n        \"AB-B0\": \"#c6ecbe\",\n        \"AB-BY\": \"#7cd892\",\n        \"Turn Claiming\": \"#f4b461\",\n        \"A0-X0\": \"#f4b461\",\n        \"A0-XA\": \"#fb9948\",\n        \"A0-XY\": \"#efa107\",\n        \"Turn Usurping\": \"#ff4d4d\",\n        \"AB-X0\": \"#ff4d4d\",\n        \"AB-XA\": \"#fb7477\",\n        \"AB-XB\": \"#ef3b6e\",\n        \"AB-XY\": \"#ef483b\",\n        \"Turn Continuing\": \"#85eff9\",\n        \"A0-AY\": \"#3b61ef\",\n        \"AB-A0\": \"#85eff9\",\n        \"AB-AY\": \"#b9befb\",\n    }\n\n    colors = [color_dict[el] for el in list(zip(*data))[1]]\n\n    if ax is None:\n        _, ax = plt.subplots()\n\n    squarify.plot(\n        list(zip(*data))[0],\n        label=labels,\n        pad=2,\n        color=colors,\n        ax=ax,\n    )\n    # plt.title(\"Participation Shifts Frequency (%)\")\n    plt.axis(\"off\")\n    return ax\n</code></pre>"},{"location":"reference/#parshift.propensities","title":"propensities","text":"<pre><code>propensities(cond_probs_df: pd.DataFrame) -&gt; pd.DataFrame\n</code></pre> <p>Determine the propensities from a conditional probabilities data frame.</p> <p>Parameters:</p> Name Type Description Default <code>cond_probs_df</code> <code>pd.DataFrame</code> <p>A data frame with statistics obtained with <code>cond_probs()</code>.</p> required <p>Returns:</p> Type Description <code>pd.DataFrame</code> <p>A data frame containing the propensities proposed by Gibson.</p> Source code in <code>/home/runner/work/parshift/parshift/parshift/statistics.py</code> <pre><code>def propensities(cond_probs_df: pd.DataFrame) -&gt; pd.DataFrame:\n\"\"\"Determine the propensities from a conditional probabilities data frame.\n\n    Arguments:\n        cond_probs_df: A data frame with statistics obtained with\n            [`cond_probs()`][parshift.statistics.cond_probs].\n\n    Returns:\n        A data frame containing the propensities proposed by Gibson.\n    \"\"\"\n\n    dic_propensities = {}\n\n    # turn-receiving propensity -&gt; AB-BA, AB-BO, and AB-BY ( P(S|D) )\n    p_s_d = cond_probs_df[\"P(S|D)\"]\n    p_s_d_c = cond_probs_df[\"P(S|D,C)\"]\n\n    dic_propensities[\"turn-receiving\"] = p_s_d[4] + p_s_d[5] + p_s_d[10]\n\n    # targeting propensity -&gt; AO-XY, AB-BY and AB-XY ( P(S|D,C) )\n    dic_propensities[\"targeting\"] = p_s_d_c[2] + p_s_d_c[10] + p_s_d_c[11]\n\n    # termination propensity -&gt; AO-AY, AB-AO and AB-AY ( P(S|D) )\n    dic_propensities[\"termination\"] = p_s_d[2] + p_s_d[9] + p_s_d[12]\n\n    return pd.DataFrame([dic_propensities])\n</code></pre>"},{"location":"reference/#parshift.pshift_class","title":"pshift_class","text":"<pre><code>pshift_class(pshift: str) -&gt; str\n</code></pre> <p>Returns the participation shift class given a participation shift code.</p> <p>Parameters:</p> Name Type Description Default <code>pshift</code> <code>str</code> <p>Participation shift code (e.g A0-XA).</p> required <p>Returns:</p> Type Description <code>str</code> <p>Participation shift classe in given the participation shift code (either \"Turn Receiving\", \"Turn Claiming\", \"Turn Usurping\" or  \"Turn Continuing\").</p> Source code in <code>/home/runner/work/parshift/parshift/parshift/annotation.py</code> <pre><code>def pshift_class(pshift: str) -&gt; str:\n\"\"\"Returns the participation shift class given a participation shift code.\n\n    Arguments:\n        pshift: Participation shift code (e.g A0-XA).\n\n    Returns:\n        Participation shift classe in given the participation shift code (either\n            \"Turn Receiving\", \"Turn Claiming\", \"Turn Usurping\" or  \"Turn Continuing\").\n    \"\"\"\n\n    if not isinstance(pshift, str):\n        raise TypeError(\"Parameter pshift_code must be a String\")\n    if not re.search(\"A[B|0]-[A|B|X][A|B|X|Y|0]\", pshift):\n        raise ValueError(\"Parameter pshift_code must be a parshift code. eg: AB-B0\")\n\n    return _p_shift_dict[pshift]\n</code></pre>"},{"location":"reference/#parshift.read_ccsv","title":"read_ccsv","text":"<pre><code>read_ccsv(\n    filepath_or_buffer: FilePath | ReadCsvBuffer[bytes] | ReadCsvBuffer[str],\n    **kwargs: Any\n) -&gt; pd.DataFrame\n</code></pre> <p>Read a conversation file in CSV format, validate it and return a data frame.</p> <p>The conversation file should have the following columns:</p> <ul> <li><code>utterance_id</code>: ID of the message (int)</li> <li><code>speaker_id</code>: ID of the user sending the message (str)</li> <li><code>utterance</code>: The message itself (string)</li> <li><code>reply_to_id</code> or <code>target_id</code>: The reply ID or the target ID (int)</li> </ul> <p>Parameters:</p> Name Type Description Default <code>filepath_or_buffer</code> <code>FilePath | ReadCsvBuffer[bytes] | ReadCsvBuffer[str]</code> <p>Any valid string path to CSV file, as accepted by Pandas <code>read_csv()</code> function.</p> required <code>**kwargs</code> <code>Any</code> <p>Keyword parameters passed to Pandas <code>read_csv()</code> function.</p> <code>{}</code> <p>Returns:</p> Type Description <code>pd.DataFrame</code> <p>A Pandas <code>DataFrame</code> containing the validated conversation.</p> Source code in <code>/home/runner/work/parshift/parshift/parshift/annotation.py</code> <pre><code>def read_ccsv(\n    filepath_or_buffer: FilePath | ReadCsvBuffer[bytes] | ReadCsvBuffer[str],\n    **kwargs: Any,\n) -&gt; pd.DataFrame:\n\"\"\"Read a conversation file in CSV format, validate it and return a data frame.\n\n    The conversation file should have the following columns:\n\n    - `utterance_id`: ID of the message (int)\n    - `speaker_id`: ID of the user sending the message (str)\n    - `utterance`: The message itself (string)\n    - `reply_to_id` or `target_id`: The reply ID or the target ID (int)\n\n    Arguments:\n        filepath_or_buffer: Any valid string path to CSV file, as accepted by\n            Pandas [`read_csv()`][pandas.read_csv] function.\n        **kwargs: Keyword parameters passed to Pandas\n            [`read_csv()`][pandas.read_csv] function.\n\n    Returns:\n        A Pandas [`DataFrame`][pandas.DataFrame] containing the validated\n            conversation.\n    \"\"\"\n\n    # Read the conversation file\n    conversation: pd.DataFrame = pd.read_csv(filepath_or_buffer, dtype=_p_shift_cols, **kwargs)  # type: ignore\n\n    # Obtain potentially missing columns\n    missing = _p_shift_cols.keys() - conversation.columns\n\n    # Check if we have missing columns\n    if (\n        len(missing) == 1\n        and \"reply_to_id\" not in missing\n        and \"target_id\" not in missing\n    ):\n        # If only one column missing, it can't be other than `reply_to_id` or `target_id`\n        raise ValueError(f\"CSV file is missing the `{missing.pop()}` column\")\n    elif len(missing) &gt; 1:\n        # If more than one column missing, we have a problem\n        raise ValueError(f\"CSV file is missing the `{'`, `'.join(missing)}` columns\")\n\n    # Change Nan values to empty strings in the `reply_to_id` or `target_id` column\n    if \"reply_to_id\" in conversation.columns:\n        conversation[\"reply_to_id\"] = conversation[\"reply_to_id\"].fillna(\"\")\n    else:\n        conversation[\"target_id\"] = conversation[\"target_id\"].fillna(\"\")\n\n    return conversation\n</code></pre>"}]}